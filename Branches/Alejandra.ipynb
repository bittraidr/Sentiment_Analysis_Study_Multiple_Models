{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ee7b7-7f06-4104-9792-c97984e139fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Joe] 1. Acquire and process stock data\n",
    "#[Alejandra]x 2. Acquire and process sentiment analysis data\n",
    "#[Session] 3. Run baseline\n",
    "#[Joe]x 4. Run sentiment analysis with LinearDiscreminateAnalysis\n",
    "#[Edward] 5. Run sentiment analysis with alternate classifier\n",
    "#[Edward] 6. Combine results\n",
    "#[Session] 7. Put together PPT preso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cee76c-678e-4d84-b510-040c69ec2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Ignore all warnings within this code block\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b36877-f199-4e5f-925d-c96261dea63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acquire and process sentiment data from Kaggle\n",
    "sentiment_df=pd.read_csv(Path(\"../Resources/combined_csv.csv\"))\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c464e3-989f-4f90-954f-68e0ac824546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain polarity and subjectivity scores (potentially factor volume of information in the sentiment analysis)\n",
    "\n",
    "# create a function to calculate the subjectivity\n",
    "def calculate_subjectivity(headlines):\n",
    "    return TextBlob(headlines).sentiment.subjectivity\n",
    "\n",
    "# create a function to calculate the subjectivity\n",
    "def calculate_polarity(headlines):\n",
    "    return TextBlob(headlines).sentiment.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ebfa4-642a-4179-9cf4-c58c0cc54d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new columns \"Subjectivity\" and \"Polarity\"\n",
    "sentiment_df[\"Subjectivity\"] = sentiment_df[\"Headline\"].apply(calculate_subjectivity)\n",
    "sentiment_df[\"Polarity\"] = sentiment_df[\"Headline\"].apply(calculate_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b4a60-8946-4cf9-ada1-48fc29c96d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get the sentiment scores \n",
    "def get_scores(headlines):\n",
    "    get_score= SentimentIntensityAnalyzer()\n",
    "    sentiment=get_score.polarity_scores(headlines)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3dcf9-5041-44e9-b079-3342c31e8d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get daily sentiment scores\n",
    "compound = []\n",
    "neg = []\n",
    "pos = []\n",
    "neu = []\n",
    "score = 0\n",
    "\n",
    "for x in range(0, len(sentiment_df[\"Headline\"])):\n",
    "    score = get_scores(sentiment_df[\"Headline\"][x])\n",
    "    compound.append(score[\"compound\"])\n",
    "    neg.append(score[\"neg\"])\n",
    "    neu.append(score[\"neu\"])\n",
    "    pos.append(score[\"pos\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb12a1-1086-4034-b5e7-65b38a352fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Column with sentiment scores\n",
    "sentiment_df[\"compound\"]= compound\n",
    "sentiment_df[\"neg\"]= neg\n",
    "sentiment_df[\"pos\"]= pos\n",
    "sentiment_df[\"neu\"]= neu\n",
    "\n",
    "#Display Dataframe\n",
    "sentiment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957f0d3-c865-4ee1-b697-8ff3a27bca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns \n",
    "sentiment_df[\"daily returns\"]= sentiment_df[\"TSLA Close\"].pct_change()\n",
    "sentiment_df.drop(columns=[\"SP500 Close\", \"Volume\"], inplace = True)\n",
    "sentiment_df= sentiment_df.set_index(\"Time\")\n",
    "sentiment_df.index= pd.to_datetime(sentiment_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebe7b9-a6d8-48fa-b4cd-ec724ad6f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label column add 1 when daily returns is positive and 0 when it is negative\n",
    "sentiment_df[\"label\"]= 0\n",
    "sentiment_df.loc[(sentiment_df[\"daily returns\"]> 0), 'label'] = 1\n",
    "\n",
    "# verify that label is int\n",
    "sentiment_df[\"label\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42be31f-ca73-4d6d-9635-0df0dcb6aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate SMA short and SMA slow\n",
    "sentiment_df[\"sma_short\"]= sentiment_df.rolling(7)[\"TSLA Close\"].mean()\n",
    "sentiment_df[\"sma_long\"]= sentiment_df.rolling(30)[\"TSLA Close\"].mean()\n",
    "sentiment_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aaa99-069b-4433-8595-7cc33a98f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display dataframe\n",
    "sentiment_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c8c8f-536c-47d8-9fd0-9da4bfc5e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features variable with columns for X\n",
    "features=['Volume.1', 'Subjectivity', 'Polarity',\n",
    "       'compound', 'neg', 'pos', 'neu', 'sma_short',\n",
    "       'sma_long']\n",
    "\n",
    "X = sentiment_df[features].shift().dropna().copy()\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a417ab-850c-4d31-a49b-d98500e4ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign label to y \n",
    "# y = sentiment_df[\"label\"][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2e5e1-f559-4a32-a3c5-2870e7990acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=(sentiment_df['daily returns']>0).astype(int)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6addb192-d4bc-493f-a36a-18094381b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify x and y are same length\n",
    "\n",
    "display(len(X))\n",
    "display(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e07ff-7c57-4546-bf6d-94467bbc6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n",
    "\n",
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=2)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "525166ae-24d3-4dbe-9d9b-09288e5c1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "10884ce4-2f04-45b8-a39b-4714dba665e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65       278\n",
      "           1       0.00      0.00      0.00       300\n",
      "\n",
      "    accuracy                           0.48       578\n",
      "   macro avg       0.24      0.50      0.32       578\n",
      "weighted avg       0.23      0.48      0.31       578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use a classifier to predict future results\n",
    "\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "svm_pred[:10]\n",
    "\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_testing_report = classification_report(y_test, svm_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b16eb-3227-43b0-8104-01038400dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df[\"TSLA Close\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefdfd9-d44b-43ca-aa85-88769ffb2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc776b-3bca-444c-9cba-d40b5e2faec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_sentiment_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_sentiment_df['Predicted'] = svm_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_sentiment_df['Actual Returns'] = sentiment_df['daily returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_sentiment_df['Strategy Returns'] = predictions_sentiment_df['Actual Returns'] * predictions_sentiment_df['Predicted'].shift()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_sentiment_df.head())\n",
    "display(predictions_sentiment_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "69a28c09-0c44-4cb0-ac61-db6a072c55fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "45821c9d-c6e7-49cc-868c-ff9f3f9b49a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0bffbce9-51e7-49de-8536-48da2be2c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59       278\n",
      "           1       0.57      0.35      0.43       300\n",
      "\n",
      "    accuracy                           0.52       578\n",
      "   macro avg       0.54      0.53      0.51       578\n",
      "weighted avg       0.54      0.52      0.51       578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085db41-f7e3-4de4-9963-c29eebcb0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Plot the actual returns versus the strategy returns\n",
    "baseline_plot = (1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod()\n",
    "baseline_plot.plot()\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
