{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "342ee7b7-7f06-4104-9792-c97984e139fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Joe] 1. Acquire and process stock data\n",
    "#[Alejandra]x 2. Acquire and process sentiment analysis data\n",
    "#[Session] 3. Run baseline\n",
    "#[Joe]x 4. Run sentiment analysis with LinearDiscreminateAnalysis\n",
    "#[Edward] 5. Run sentiment analysis with alternate classifier\n",
    "#[Edward] 6. Combine results\n",
    "#[Session] 7. Put together PPT preso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cee76c-678e-4d84-b510-040c69ec2b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvaderSentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvaderSentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "# Ignore all warnings within this code block\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8135f0-1413-465f-8d7b-5121b090dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Acquire and process data\n",
    "\n",
    "# ## Acquire and process stock data\n",
    "\n",
    "# # create dataframe for stock close data from yfinance (csv files)\n",
    "# start_date = '2020-01-01'\n",
    "# end_date = '2023-08-31'\n",
    "\n",
    "# stock_symbol = 'TSLA'\n",
    "\n",
    "# stock_df = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# # stock_df.to_csv(Path('Resources/sp500.csv'))\n",
    "\n",
    "# # drop all columns other than 'Date', 'Close', and 'Volume'\n",
    "\n",
    "# # adjust the Date datetime format\n",
    "\n",
    "# # set the Date column as index\n",
    "\n",
    "# # create a column for returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d47eb-5c41-41d9-b467-a4fd52ad061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acquire and process sentiment data from Kaggle\n",
    "sentiment_df=pd.read_csv(Path(\"../Resources/combined_csv.csv\"))\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b36877-f199-4e5f-925d-c96261dea63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain polarity and subjectivity scores (potentially factor volume of information in the sentiment analysis)\n",
    "\n",
    "# create a function to calculate the subjectivity\n",
    "def calculate_subjectivity(headlines):\n",
    "    return TextBlob(headlines).sentiment.subjectivity\n",
    "\n",
    "# create a function to calculate the subjectivity\n",
    "def calculate_polarity(headlines):\n",
    "    return TextBlob(headlines).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbdf55-579b-48ef-b796-8af057c26dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new columns \"Subjectivity\" and \"Polarity\"\n",
    "sentiment_df[\"Subjectivity\"] = sentiment_df[\"Headline\"].apply(calculate_subjectivity)\n",
    "sentiment_df[\"Polarity\"] = sentiment_df[\"Headline\"].apply(calculate_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29814f0d-a7df-48f1-9bb0-050157898eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get the sentiment scores \n",
    "def get_scores(headlines):\n",
    "    get_score= SentimentIntensityAnalyzer()\n",
    "    sentiment=get_score.polarity_scores(headlines)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2f1c7-2a55-45d6-8afd-2c419bf74ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get daily sentiment scores\n",
    "compound = []\n",
    "neg = []\n",
    "pos = []\n",
    "neu = []\n",
    "score = 0\n",
    "\n",
    "for x in range(0, len(sentiment_df[\"Headline\"])):\n",
    "    score = get_scores(sentiment_df[\"Headline\"][x])\n",
    "    compound.append(score[\"compound\"])\n",
    "    neg.append(score[\"neg\"])\n",
    "    neu.append(score[\"neu\"])\n",
    "    pos.append(score[\"pos\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a44ada-3d05-4a55-89d0-ae12a93e967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Column with sentiment scores\n",
    "sentiment_df[\"compound\"]= compound\n",
    "sentiment_df[\"neg\"]= neg\n",
    "sentiment_df[\"pos\"]= pos\n",
    "sentiment_df[\"neu\"]= neu\n",
    "\n",
    "#Display Dataframe\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aad6d4-dab8-499f-a6e1-b78680fe3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run baseline prediction with moving average windows\n",
    "\n",
    "## Generate trading signals using short- and long-window SMA values\n",
    "\n",
    "# Set the short window and long window\n",
    "short_window = 4\n",
    "long_window = 100\n",
    "\n",
    "# Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(signals_df.head())\n",
    "# display(signals_df.tail())\n",
    "\n",
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0.0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(signals_df.head())\n",
    "# display(signals_df.tail())\n",
    "\n",
    "# Review the split of the signals\n",
    "signals_df['Signal'].value_counts()\n",
    "\n",
    "# Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "\n",
    "# Plot Strategy Returns to examine performance\n",
    "(1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0467b-4e8e-4fce-9257-123919953a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing datasets\n",
    "\n",
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "\n",
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = signals_df['Signal']\n",
    "\n",
    "# Review the value counts\n",
    "y.value_counts()\n",
    "\n",
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n",
    "\n",
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486b592-3f02-4525-8b27-66ab0077c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10884ce4-2f04-45b8-a39b-4714dba665e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use a classifier to predict future results\n",
    "\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "svm_pred[:10]\n",
    "\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_testing_report = classification_report(y_test, svm_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = svm_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df['Actual Returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns'] = predictions_df['Actual Returns'] * predictions_df['Predicted'].shift()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df.head())\n",
    "display(predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085db41-f7e3-4de4-9963-c29eebcb0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Plot the actual returns versus the strategy returns\n",
    "baseline_plot = (1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod()\n",
    "baseline_plot.plot()\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa575df0-ae91-4d95-a5a7-9388515a99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run LinearDiscreminateAnalysis to create predictions with sentiment analysis\n",
    "\n",
    "## Generate trading signals based on sentiments\n",
    "\n",
    "## Split the data into training and testing datasets\n",
    "\n",
    "## Scale the features DataFrames\n",
    "\n",
    "## Use a classifier to predict future results\n",
    "\n",
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67d5d7-aec9-43a9-a4e1-8e205e32fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run XXX to create predictions with sentiment analysis [Copy the classification code for the LinearDiscreminateAnalysis above]\n",
    "\n",
    "## Use a classifier to predict future results\n",
    "\n",
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9f3ea-5af2-4288-9154-0cb86e76a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate results\n",
    "\n",
    "## Combine the plots of the baseline and the ML models using sentiment analysis\n",
    "\n",
    "## Display the various classification reports\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
