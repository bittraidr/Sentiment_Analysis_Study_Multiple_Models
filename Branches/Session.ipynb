{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342ee7b7-7f06-4104-9792-c97984e139fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[Joe] 1. Acquire and process stock data\n",
    "#[Alejandra]x 2. Acquire and process sentiment analysis data\n",
    "#[Session] 3. Run baseline\n",
    "#[Joe]x 4. Run sentiment analysis with LinearDiscreminateAnalysis\n",
    "#[Edward] 5. Run sentiment analysis with alternate classifier\n",
    "#[Edward] 6. Combine results\n",
    "#[Session] 7. Put together PPT preso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cee76c-678e-4d84-b510-040c69ec2b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings within this code block\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8135f0-1413-465f-8d7b-5121b090dee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Acquire and process data\n",
    "\n",
    "## Acquire and process stock data\n",
    "\n",
    "# create dataframe for stock close data from yfinance (csv files)\n",
    "# start_date = '2020-01-01'\n",
    "# end_date = '2023-08-31'\n",
    "\n",
    "# stock_symbol = 'TSLA'\n",
    "\n",
    "# stock_df = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# stock_df.to_csv(Path('Resources/sp500.csv'))\n",
    "\n",
    "# drop all columns other than 'Date', 'Close', and 'Volume'\n",
    "\n",
    "# adjust the Date datetime format\n",
    "\n",
    "# set the Date column as index\n",
    "\n",
    "# create a column for returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b36877-f199-4e5f-925d-c96261dea63a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Acquire and process sentiment data from Kaggle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# create a dataframe that concatenate all of the headline files\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43msentiment_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentiment_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Acquire and process sentiment data from Kaggle\n",
    "\n",
    "# create a dataframe that concatenate all of the headline files\n",
    "sentiment_df\n",
    "\n",
    "# clean the sentiment dataframe\n",
    "\n",
    "# obtain polarity and subjectivity scores (potentially factor volume of information in the sentiment analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aad6d4-dab8-499f-a6e1-b78680fe3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run baseline prediction with moving average windows\n",
    "\n",
    "## Generate trading signals using short- and long-window SMA values\n",
    "\n",
    "# Set the short window and long window\n",
    "short_window = 4\n",
    "long_window = 100\n",
    "\n",
    "# Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(signals_df.head())\n",
    "# display(signals_df.tail())\n",
    "\n",
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0.0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(signals_df.head())\n",
    "# display(signals_df.tail())\n",
    "\n",
    "# Review the split of the signals\n",
    "signals_df['Signal'].value_counts()\n",
    "\n",
    "# Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "\n",
    "# Plot Strategy Returns to examine performance\n",
    "(1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0467b-4e8e-4fce-9257-123919953a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing datasets\n",
    "\n",
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "\n",
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = signals_df['Signal']\n",
    "\n",
    "# Review the value counts\n",
    "y.value_counts()\n",
    "\n",
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n",
    "\n",
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486b592-3f02-4525-8b27-66ab0077c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10884ce4-2f04-45b8-a39b-4714dba665e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use a classifier to predict future results\n",
    "\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "svm_pred[:10]\n",
    "\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_testing_report = classification_report(y_test, svm_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = svm_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df['Actual Returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns'] = predictions_df['Actual Returns'] * predictions_df['Predicted'].shift()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df.head())\n",
    "display(predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085db41-f7e3-4de4-9963-c29eebcb0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Plot the actual returns versus the strategy returns\n",
    "baseline_plot = (1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod()\n",
    "baseline_plot.plot()\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa575df0-ae91-4d95-a5a7-9388515a99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run LinearDiscreminateAnalysis to create predictions with sentiment analysis\n",
    "\n",
    "## Generate trading signals based on sentiments\n",
    "\n",
    "## Split the data into training and testing datasets\n",
    "\n",
    "## Scale the features DataFrames\n",
    "\n",
    "## Use a classifier to predict future results\n",
    "\n",
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67d5d7-aec9-43a9-a4e1-8e205e32fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run XXX to create predictions with sentiment analysis [Copy the classification code for the LinearDiscreminateAnalysis above]\n",
    "\n",
    "## Use a classifier to predict future results\n",
    "\n",
    "## Plot cummulative returns for the baseline model\n",
    "\n",
    "# Save the baseline plot to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9f3ea-5af2-4288-9154-0cb86e76a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate results\n",
    "\n",
    "## Combine the plots of the baseline and the ML models using sentiment analysis\n",
    "\n",
    "## Display the various classification reports\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
